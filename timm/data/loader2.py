from timm.data.loader import fast_collate, create_transform

from timm.data.datapipe import create_datapipe
from torch.utils.data import default_collate
from torchdata.datapipes.iter import IterDataPipe
from torchdata.dataloader2 import DataLoader2
from torchdata.dataloader2.reading_service import (
    DistributedReadingService,
    MultiProcessingReadingService,
    SequentialReadingService,
)
from typing import Callable


def create_loader2(
        datapipe: IterDataPipe,
        batch_size: int,
        is_training: bool,
        dataset_len: int,
        img_transform: Callable = None,  # Generated by `create_transform`
        collate_fn: Callable = None,
        pin_memory: bool = False,
        num_workers: int = 0,
        use_prefetcher: bool = True,  # Enabled by MultiProcessingReadingService by default
        distributed: bool = False,
   ):
    r"""
    Given a `datapipe` of decoded files, create a `DataLoader2` with proper `ReadingService` settings
    after applying transform, batching, collation to samples from `datapipe`.

    Colab example:
    https://colab.research.google.com/drive/1eSvp-eUDYPj0Sd0X_Mv9s9VkE8RNDg1u#scrollTo=Xnv9gwsabigV
    """
    if img_transform is not None:
        datapipe = datapipe.map(img_transform, input_col=0)  # Apply `img_transform` to `image`
    datapipe = datapipe.batch(batch_size, drop_last=is_training)
    if collate_fn is None:
        collate_fn = fast_collate if use_prefetcher else default_collate
        datapipe = datapipe.collate(collate_fn=collate_fn)
    # Note: Depending on what the transform/collation is, it may need to invoke `img.float()` for certain models here
    if pin_memory:
        datapipe = datapipe.pin_memory()

    # Shuffle batches
    datapipe = datapipe.shuffle()

    # Note: `DataLoader2` doesn't implement `__len__` method at the moment.
    # Manually setting DataPipe length is recommended because many DataPipe operations do not know
    # the resulting length in advance.
    length = dataset_len // batch_size if is_training else (dataset_len // batch_size) + 1
    datapipe = datapipe.set_length(length)

    prefetch_cnt = {} if use_prefetcher else {"worker_prefetch_cnt": 0, "main_prefetch_cnt": 0}

    # `MultiProcessingReadingService`, similar to old `DataLoader`, defines the multiprocessing behavior.
    mp_rs = MultiProcessingReadingService(num_workers=num_workers, **prefetch_cnt)

    if distributed:
        # `DistributedReadingService` handles distributed setting, seeding and unevenly sharded data (by stopping
        #  when the shortest distributed shard is exhausted).
        dist_rs = DistributedReadingService()
        # `SequentialReadingService` allows us to use multiple ReadingServices at the same time
        # In distributed training, we typically use both Distributed and Multiprocessing at the same time.
        rs = SequentialReadingService(dist_rs, mp_rs)
    else:
        # Without distributed, we can use `MultiProcessingReadingService` as a standalone.
        rs = mp_rs

    dl = DataLoader2(datapipe, reading_service=rs)
    return dl


def _get_open_port():
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    s.bind(("", 0))
    port = s.getsockname()[1]
    s.close()
    return str(port)


def mp_distributed_training(dp, dataset_len: int, num_workers: int, batch_size: int, transform, rank: int, world_size: int, q):
    dist.init_process_group("gloo", rank=rank, world_size=world_size)
    dl = create_loader2(dp, batch_size=batch_size, is_training=True, dataset_len=dataset_len,
                        num_workers=num_workers, img_transform=transform, distributed=True)
    cnt = 0
    for d in dl:
        cnt += 1
        # Mimic distributed training step
        dist.barrier()
    q.put(cnt)
    dl.shutdown()


if __name__ == "__main__":
    """
    Example script for using `DataLoader2` by itself.
    """
    root = "."
    distributed = False
    batch_size = 16
    num_workers = 8
    dp = create_datapipe(name="ImageNet", root=root, split="valid")
    transform = create_transform(input_size=(3, 224, 224))
    dataset_len = 1000  # Just for example

    if distributed:
        import torch.distributed as dist
        import torch.multiprocessing as mp
        import socket
        import os

        MASTER_ADDR = "127.0.0.1"
        WORLD_SIZE = 2
        os.environ["MASTER_ADDR"] = MASTER_ADDR
        os.environ["MASTER_PORT"] = _get_open_port()

        ctx = mp.get_context("fork")  # can use other methods as well
        pqs = []
        for rank in range(WORLD_SIZE):
            q = ctx.Queue()
            p = ctx.Process(target=mp_distributed_training,
                            args=(dp, dataset_len, num_workers, batch_size, transform, rank, WORLD_SIZE, q))
            pqs.append((p, q))
            p.start()

        for rank in range(WORLD_SIZE):
            cnt = pqs[rank][1].get()
            print(f"DataLoader2 on rank {rank} received {cnt} data")
            pqs[rank][0].join()

    else:  # `distributed == False`, only multiprocessing is used.
        dl = create_loader2(dp, batch_size=batch_size, is_training=True,
                            dataset_len=dataset_len, num_workers=num_workers, img_transform=transform)
        for batch in dl:
            print(batch)
        dl.shutdown()
